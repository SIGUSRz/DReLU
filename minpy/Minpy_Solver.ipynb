{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy.random:__init__:30]\u001b[0m Initialize module: minpy.numpy.random.\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy.random:__init__:38]\u001b[0m Importing from minpy.array_variants.numpy.random.\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy.random:__init__:45]\u001b[0m Got 53 primitives from minpy.array_variants.numpy.random\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy.random:__init__:38]\u001b[0m Importing from minpy.array_variants.mxnet.random.\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy.random:__init__:45]\u001b[0m Got 2 primitives from minpy.array_variants.mxnet.random\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy.random:__init__:50]\u001b[0m Import 55 primitives\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy:__init__:30]\u001b[0m Initialize module: minpy.numpy.\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy:__init__:38]\u001b[0m Importing from minpy.array_variants.numpy.\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy:__init__:45]\u001b[0m Got 396 primitives from minpy.array_variants.numpy\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy:__init__:38]\u001b[0m Importing from minpy.array_variants.mxnet.\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy:__init__:45]\u001b[0m Got 35 primitives from minpy.array_variants.mxnet\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy:__init__:50]\u001b[0m Import 431 primitives\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.pkl exits\n",
      "train-labels-idx1-ubyte.pkl exits\n",
      "t10k-images-idx3-ubyte.pkl exits\n",
      "t10k-labels-idx1-ubyte.pkl exits\n",
      "(59000, 28, 28)\n",
      "(59000,)\n",
      "(1000, 28, 28)\n",
      "(1000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import minpy.numpy as np\n",
    "import load_data\n",
    "num_val = 1000\n",
    "num_train = 60000 - num_val\n",
    "num_test = 10000\n",
    "batch_size = 128\n",
    "cifar_path = 'Datasets/cifar-10/'\n",
    "mnist_path = 'Datasets/mnist/'\n",
    "\n",
    "def get_data(path,num_train,num_val,num_test):\n",
    "    x_train,y_train,x_test,y_test = load_data.load_MNIST(path)\n",
    "    x_val = x_train[num_train:num_train+num_val]\n",
    "    y_val = y_train[num_train:num_train+num_val]\n",
    "    y_val = y_val.reshape(y_val.shape[0])\n",
    "    x_train = x_train[:num_train]\n",
    "    y_train = y_train[:num_train]\n",
    "    y_train = y_train.reshape(y_train.shape[0])\n",
    "    x_test = x_test[:num_test]\n",
    "    y_test = y_test[:num_test]\n",
    "    y_test = y_test.reshape(y_test.shape[0])\n",
    "    return x_train,y_train,x_val,y_val,x_test,y_test\n",
    "x_train,y_train,x_val,y_val,x_test,y_test = get_data(mnist_path,num_train,num_val,num_test)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy:__getattr__:67]\u001b[0m No entry found for \"random\" in registry, fallback.\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy:__getattr__:67]\u001b[0m No entry found for \"random\" in registry, fallback.\n",
      "\u001b[32mI0620 15:55:54 5666 minpy.numpy:__getattr__:67]\u001b[0m No entry found for \"random\" in registry, fallback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(59000, 784) (59000,) (1000, 784) (1000,) (10000, 784) (10000,)\n",
      "epoch 0 batch 0 loss: 6.933524\n",
      "epoch 0 batch 50 loss: 6.963250\n",
      "epoch 0 batch 100 loss: 6.951446\n",
      "epoch 0 batch 150 loss: 6.931808\n",
      "epoch 0 batch 200 loss: 6.958004\n",
      "epoch 0 batch 250 loss: 6.967346\n",
      "epoch 0 batch 300 loss: 6.930924\n",
      "epoch 0 batch 350 loss: 6.943575\n",
      "epoch 0 batch 400 loss: 6.952963\n",
      "epoch 0 batch 450 loss: 6.950781\n",
      "epoch 0 batch 500 loss: 6.939992\n",
      "epoch 0 batch 550 loss: 6.930333\n",
      "epoch 0 batch 600 loss: 6.937618\n",
      "epoch 0 batch 650 loss: 6.936848\n",
      "epoch 0 batch 700 loss: 6.960321\n",
      "epoch 0 batch 750 loss: 6.946413\n",
      "epoch 0 batch 800 loss: 6.953018\n",
      "epoch 0 batch 850 loss: 6.922330\n",
      "epoch 0 batch 900 loss: 6.944438\n",
      "epoch 0 batch 950 loss: 6.948965\n",
      "epoch 0 batch 1000 loss: 6.922986\n",
      "epoch 0 batch 1050 loss: 6.957470\n",
      "epoch 0 batch 1100 loss: 6.958534\n",
      "epoch 0 batch 1150 loss: 6.962512\n",
      "epoch 0 validation accuracy: 1.000000\n",
      "optimal accuracy: 1.000000\n",
      "test accuracy: 1.000000\n",
      "epoch 1 batch 0 loss: 6.933524\n",
      "epoch 1 batch 50 loss: 6.963250\n",
      "epoch 1 batch 100 loss: 6.951446\n",
      "epoch 1 batch 150 loss: 6.931808\n",
      "epoch 1 batch 200 loss: 6.958004\n",
      "epoch 1 batch 250 loss: 6.967346\n",
      "epoch 1 batch 300 loss: 6.930924\n",
      "epoch 1 batch 350 loss: 6.943575\n",
      "epoch 1 batch 400 loss: 6.952963\n",
      "epoch 1 batch 450 loss: 6.950781\n",
      "epoch 1 batch 500 loss: 6.939992\n",
      "epoch 1 batch 550 loss: 6.930333\n",
      "epoch 1 batch 600 loss: 6.937618\n",
      "epoch 1 batch 650 loss: 6.936848\n",
      "epoch 1 batch 700 loss: 6.960321\n",
      "epoch 1 batch 750 loss: 6.946413\n",
      "epoch 1 batch 800 loss: 6.953018\n",
      "epoch 1 batch 850 loss: 6.922330\n",
      "epoch 1 batch 900 loss: 6.944438\n",
      "epoch 1 batch 950 loss: 6.948965\n",
      "epoch 1 batch 1000 loss: 6.922986\n",
      "epoch 1 batch 1050 loss: 6.957470\n",
      "epoch 1 batch 1100 loss: 6.958534\n",
      "epoch 1 batch 1150 loss: 6.962512\n",
      "epoch 1 validation accuracy: 1.000000\n",
      "optimal accuracy: 1.000000\n",
      "test accuracy: 1.000000\n",
      "epoch 2 batch 0 loss: 6.933524\n",
      "epoch 2 batch 50 loss: 6.963250\n",
      "epoch 2 batch 100 loss: 6.951446\n",
      "epoch 2 batch 150 loss: 6.931808\n",
      "epoch 2 batch 200 loss: 6.958004\n",
      "epoch 2 batch 250 loss: 6.967346\n",
      "epoch 2 batch 300 loss: 6.930924\n",
      "epoch 2 batch 350 loss: 6.943575\n",
      "epoch 2 batch 400 loss: 6.952963\n",
      "epoch 2 batch 450 loss: 6.950781\n",
      "epoch 2 batch 500 loss: 6.939992\n",
      "epoch 2 batch 550 loss: 6.930333\n",
      "epoch 2 batch 600 loss: 6.937618\n",
      "epoch 2 batch 650 loss: 6.936848\n",
      "epoch 2 batch 700 loss: 6.960321\n",
      "epoch 2 batch 750 loss: 6.946413\n",
      "epoch 2 batch 800 loss: 6.953018\n",
      "epoch 2 batch 850 loss: 6.922330\n",
      "epoch 2 batch 900 loss: 6.944438\n",
      "epoch 2 batch 950 loss: 6.948965\n",
      "epoch 2 batch 1000 loss: 6.922986\n",
      "epoch 2 batch 1050 loss: 6.957470\n",
      "epoch 2 batch 1100 loss: 6.958534\n",
      "epoch 2 batch 1150 loss: 6.962512\n",
      "epoch 2 validation accuracy: 1.000000\n",
      "optimal accuracy: 1.000000\n",
      "test accuracy: 1.000000\n",
      "epoch 3 batch 0 loss: 6.933524\n",
      "epoch 3 batch 50 loss: 6.963250\n",
      "epoch 3 batch 100 loss: 6.951446\n",
      "epoch 3 batch 150 loss: 6.931808\n",
      "epoch 3 batch 200 loss: 6.958004\n",
      "epoch 3 batch 250 loss: 6.967346\n",
      "epoch 3 batch 300 loss: 6.930924\n",
      "epoch 3 batch 350 loss: 6.943575\n",
      "epoch 3 batch 400 loss: 6.952963\n",
      "epoch 3 batch 450 loss: 6.950781\n",
      "epoch 3 batch 500 loss: 6.939992\n",
      "epoch 3 batch 550 loss: 6.930333\n",
      "epoch 3 batch 600 loss: 6.937618\n",
      "epoch 3 batch 650 loss: 6.936848\n",
      "epoch 3 batch 700 loss: 6.960321\n",
      "epoch 3 batch 750 loss: 6.946413\n",
      "epoch 3 batch 800 loss: 6.953018\n",
      "epoch 3 batch 850 loss: 6.922330\n",
      "epoch 3 batch 900 loss: 6.944438\n",
      "epoch 3 batch 950 loss: 6.948965\n",
      "epoch 3 batch 1000 loss: 6.922986\n",
      "epoch 3 batch 1050 loss: 6.957470\n",
      "epoch 3 batch 1100 loss: 6.958534\n",
      "epoch 3 batch 1150 loss: 6.962512\n",
      "epoch 3 validation accuracy: 1.000000\n",
      "optimal accuracy: 1.000000\n",
      "test accuracy: 1.000000\n",
      "epoch 4 batch 0 loss: 6.933524\n"
     ]
    }
   ],
   "source": [
    "from model_zoo import *\n",
    "from solver import *\n",
    "_,H,W = x_train.shape\n",
    "D = H * W\n",
    "model = mlp()\n",
    "data = (x_train.reshape(x_train.shape[0],D), y_train, \n",
    "        x_val.reshape(x_val.shape[0],D), y_val, \n",
    "        x_test.reshape(x_test.shape[0],D), y_test)\n",
    "setting = {\n",
    "    'epoch': 30,\n",
    "    'batch_size': 50,\n",
    "    'decay_rate': 0.9,\n",
    "    'decay_interval': 5,\n",
    "    'optimizer': 'sgd',\n",
    "    'update_setting': {'learning_rate': 0.2},\n",
    "}\n",
    "solver = Solver(model, data, **setting)\n",
    "accuracy = solver.train()\n",
    "print accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print 'Program End Flag'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
