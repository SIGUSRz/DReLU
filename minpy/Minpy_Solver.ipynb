{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '3'\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "# This is a bit of magic to make matplotlib figures appear inline in the notebook\n",
    "# rather than in a new window.\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# Some more magic so that the notebook will reload external python modules;\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy.random:__init__:30]\u001b[0m Initialize module: minpy.numpy.random.\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy.random:__init__:38]\u001b[0m Importing from minpy.array_variants.numpy.random.\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy.random:__init__:45]\u001b[0m Got 53 primitives from minpy.array_variants.numpy.random\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy.random:__init__:38]\u001b[0m Importing from minpy.array_variants.mxnet.random.\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy.random:__init__:45]\u001b[0m Got 2 primitives from minpy.array_variants.mxnet.random\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy.random:__init__:50]\u001b[0m Import 55 primitives\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy:__init__:30]\u001b[0m Initialize module: minpy.numpy.\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy:__init__:38]\u001b[0m Importing from minpy.array_variants.numpy.\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy:__init__:45]\u001b[0m Got 396 primitives from minpy.array_variants.numpy\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy:__init__:38]\u001b[0m Importing from minpy.array_variants.mxnet.\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy:__init__:45]\u001b[0m Got 36 primitives from minpy.array_variants.mxnet\n",
      "\u001b[32mI0717 18:33:10 13785 minpy.numpy:__init__:50]\u001b[0m Import 432 primitives\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train-images-idx3-ubyte.pkl exits\n",
      "train-labels-idx1-ubyte.pkl exits\n",
      "t10k-images-idx3-ubyte.pkl exits\n",
      "t10k-labels-idx1-ubyte.pkl exits\n",
      "(50000, 28, 28)\n",
      "(50000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "import minpy.numpy as np\n",
    "import load_data\n",
    "num_val = 10000\n",
    "num_train = 60000 - num_val\n",
    "num_test = 10000\n",
    "batch_size = 128\n",
    "cifar_path = 'Datasets/cifar-10/'\n",
    "mnist_path = 'Datasets/mnist/'\n",
    "\n",
    "def get_data(path,num_train,num_val,num_test):\n",
    "    x_train,y_train,x_test,y_test = load_data.load_MNIST(path)\n",
    "    x_val = x_train[num_train:num_train+num_val]\n",
    "    y_val = y_train[num_train:num_train+num_val]\n",
    "    y_val = y_val.reshape(y_val.shape[0])\n",
    "    x_train = x_train[:num_train]\n",
    "    y_train = y_train[:num_train]\n",
    "    y_train = y_train.reshape(y_train.shape[0])\n",
    "    x_test = x_test[:num_test]\n",
    "    y_test = y_test[:num_test]\n",
    "    y_test = y_test.reshape(y_test.shape[0])\n",
    "    return x_train,y_train,x_val,y_val,x_test,y_test\n",
    "x_train,y_train,x_val,y_val,x_test,y_test = get_data(mnist_path,num_train,num_val,num_test)\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_val.shape)\n",
    "print(y_val.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "_,H,W = x_train.shape\n",
    "D = H * W\n",
    "data = (x_train.reshape(x_train.shape[0],D), y_train, \n",
    "        x_val.reshape(x_val.shape[0],D), y_val, \n",
    "        x_test.reshape(x_test.shape[0],D), y_test)\n",
    "# data = (x_train.reshape(x_train.shape[0],D), np.reshape(y_train,(y_train.shape[0], 1)),\n",
    "#         x_val.reshape(x_val.shape[0],D), np.reshape(y_val, (y_val.shape[0], 1)), \n",
    "#         x_test.reshape(x_test.shape[0],D), np.reshape(y_test, (y_test.shape[0], 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mI0717 18:33:11 13785 minpy.numpy:__getattr__:69]\u001b[0m No entry found for \"random\" in registry, fallback.\n",
      "\u001b[32mI0717 18:33:11 13785 minpy.numpy:__getattr__:69]\u001b[0m No entry found for \"random\" in registry, fallback.\n",
      "\u001b[32mI0717 18:33:11 13785 minpy.numpy:__getattr__:69]\u001b[0m No entry found for \"random\" in registry, fallback.\n",
      "\u001b[32mI0717 18:33:11 13785 minpy.numpy:__getattr__:69]\u001b[0m No entry found for \"random\" in registry, fallback.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 batch 0 loss: 2.297732\n",
      "epoch 0 batch 50 loss: 1.718443\n",
      "epoch 0 batch 100 loss: 0.987623\n",
      "epoch 0 batch 150 loss: 0.694262\n",
      "epoch 0 batch 200 loss: 0.613447\n",
      "epoch 0 batch 250 loss: 0.989697\n",
      "epoch 0 batch 300 loss: 0.229101\n",
      "epoch 0 batch 350 loss: 0.319833\n",
      "epoch 0 batch 400 loss: 0.391129\n",
      "epoch 0 batch 450 loss: 0.518931\n",
      "epoch 0 batch 500 loss: 0.137738\n",
      "epoch 0 batch 550 loss: 0.286954\n",
      "epoch 0 batch 600 loss: 0.220890\n",
      "epoch 0 batch 650 loss: 0.168049\n",
      "epoch 0 batch 700 loss: 0.036449\n",
      "epoch 0 batch 750 loss: 0.157692\n",
      "epoch 0 batch 800 loss: 0.099194\n",
      "epoch 0 batch 850 loss: 0.435978\n",
      "epoch 0 batch 900 loss: 0.119452\n",
      "epoch 0 batch 950 loss: 0.222910\n",
      "validation accuracy: 0.952200\n",
      "test accuracy: 0.948100\n",
      "optimal accuracy: 0.952200\n",
      "epoch 1 batch 0 loss: 0.213206\n",
      "epoch 1 batch 50 loss: 0.026979\n",
      "epoch 1 batch 100 loss: 0.076019\n",
      "epoch 1 batch 150 loss: 0.211998\n",
      "epoch 1 batch 200 loss: 0.190202\n",
      "epoch 1 batch 250 loss: 0.173760\n",
      "epoch 1 batch 300 loss: 0.106505\n",
      "epoch 1 batch 350 loss: 0.097763\n",
      "epoch 1 batch 400 loss: 0.182713\n",
      "epoch 1 batch 450 loss: 0.298177\n",
      "epoch 1 batch 500 loss: 0.012499\n",
      "epoch 1 batch 550 loss: 0.237167\n",
      "epoch 1 batch 600 loss: 0.174278\n",
      "epoch 1 batch 650 loss: 0.018893\n",
      "epoch 1 batch 700 loss: 0.025769\n",
      "epoch 1 batch 750 loss: 0.229696\n",
      "epoch 1 batch 800 loss: 0.061884\n",
      "epoch 1 batch 850 loss: 0.173412\n",
      "epoch 1 batch 900 loss: 0.054475\n",
      "epoch 1 batch 950 loss: 0.074533\n",
      "validation accuracy: 0.962900\n",
      "test accuracy: 0.960600\n",
      "optimal accuracy: 0.962900\n",
      "epoch 2 batch 0 loss: 0.105329\n",
      "epoch 2 batch 50 loss: 0.013556\n",
      "epoch 2 batch 100 loss: 0.014654\n",
      "epoch 2 batch 150 loss: 0.079178\n",
      "epoch 2 batch 200 loss: 0.167755\n",
      "epoch 2 batch 250 loss: 0.057451\n",
      "epoch 2 batch 300 loss: 0.032087\n",
      "epoch 2 batch 350 loss: 0.039097\n",
      "epoch 2 batch 400 loss: 0.108725\n",
      "epoch 2 batch 450 loss: 0.101413\n",
      "epoch 2 batch 500 loss: 0.007201\n",
      "epoch 2 batch 550 loss: 0.180244\n",
      "epoch 2 batch 600 loss: 0.130404\n",
      "epoch 2 batch 650 loss: 0.011220\n",
      "epoch 2 batch 700 loss: 0.057543\n",
      "epoch 2 batch 750 loss: 0.119134\n",
      "epoch 2 batch 800 loss: 0.062650\n",
      "epoch 2 batch 850 loss: 0.129240\n",
      "epoch 2 batch 900 loss: 0.034478\n",
      "epoch 2 batch 950 loss: 0.028335\n",
      "validation accuracy: 0.964400\n",
      "test accuracy: 0.965500\n",
      "optimal accuracy: 0.964400\n",
      "epoch 3 batch 0 loss: 0.046311\n",
      "epoch 3 batch 50 loss: 0.014890\n",
      "epoch 3 batch 100 loss: 0.005524\n",
      "epoch 3 batch 150 loss: 0.045424\n",
      "epoch 3 batch 200 loss: 0.111412\n",
      "epoch 3 batch 250 loss: 0.018798\n",
      "epoch 3 batch 300 loss: 0.006880\n",
      "epoch 3 batch 350 loss: 0.031527\n",
      "epoch 3 batch 400 loss: 0.101852\n",
      "epoch 3 batch 450 loss: 0.087084\n",
      "epoch 3 batch 500 loss: 0.011568\n",
      "epoch 3 batch 550 loss: 0.109234\n",
      "epoch 3 batch 600 loss: 0.034917\n",
      "epoch 3 batch 650 loss: 0.009638\n",
      "epoch 3 batch 700 loss: 0.028740\n",
      "epoch 3 batch 750 loss: 0.037894\n",
      "epoch 3 batch 800 loss: 0.032448\n",
      "epoch 3 batch 850 loss: 0.049214\n",
      "epoch 3 batch 900 loss: 0.041961\n",
      "epoch 3 batch 950 loss: 0.014131\n",
      "validation accuracy: 0.968000\n",
      "test accuracy: 0.969000\n",
      "optimal accuracy: 0.968000\n",
      "epoch 4 batch 0 loss: 0.017627\n",
      "epoch 4 batch 50 loss: 0.002212\n",
      "epoch 4 batch 100 loss: 0.008907\n",
      "epoch 4 batch 150 loss: 0.016073\n",
      "epoch 4 batch 200 loss: 0.060492\n",
      "epoch 4 batch 250 loss: 0.038339\n",
      "epoch 4 batch 300 loss: 0.003923\n",
      "epoch 4 batch 350 loss: 0.021287\n",
      "epoch 4 batch 400 loss: 0.065381\n",
      "epoch 4 batch 450 loss: 0.043026\n",
      "epoch 4 batch 500 loss: 0.008149\n",
      "epoch 4 batch 550 loss: 0.058164\n",
      "epoch 4 batch 600 loss: 0.042373\n",
      "epoch 4 batch 650 loss: 0.005310\n",
      "epoch 4 batch 700 loss: 0.086366\n",
      "epoch 4 batch 750 loss: 0.046729\n",
      "epoch 4 batch 800 loss: 0.068177\n",
      "epoch 4 batch 850 loss: 0.089731\n",
      "epoch 4 batch 900 loss: 0.004953\n",
      "epoch 4 batch 950 loss: 0.037043\n",
      "validation accuracy: 0.963700\n",
      "test accuracy: 0.969000\n",
      "optimal accuracy: 0.968000\n",
      "learning rate decayed to 0.207000\n",
      "epoch 5 batch 0 loss: 0.017627\n",
      "epoch 5 batch 50 loss: 0.001482\n",
      "epoch 5 batch 100 loss: 0.006362\n",
      "epoch 5 batch 150 loss: 0.018099\n",
      "epoch 5 batch 200 loss: 0.047837\n",
      "epoch 5 batch 250 loss: 0.055036\n",
      "epoch 5 batch 300 loss: 0.003116\n",
      "epoch 5 batch 350 loss: 0.014702\n",
      "epoch 5 batch 400 loss: 0.100259\n",
      "epoch 5 batch 450 loss: 0.038134\n",
      "epoch 5 batch 500 loss: 0.002410\n",
      "epoch 5 batch 550 loss: 0.047667\n",
      "epoch 5 batch 600 loss: 0.022443\n",
      "epoch 5 batch 650 loss: 0.011751\n",
      "epoch 5 batch 700 loss: 0.078292\n",
      "epoch 5 batch 750 loss: 0.033526\n",
      "epoch 5 batch 800 loss: 0.052589\n",
      "epoch 5 batch 850 loss: 0.059350\n",
      "epoch 5 batch 900 loss: 0.020071\n",
      "epoch 5 batch 950 loss: 0.015010\n",
      "validation accuracy: 0.969600\n",
      "test accuracy: 0.969700\n",
      "optimal accuracy: 0.969600\n",
      "epoch 6 batch 0 loss: 0.015794\n",
      "epoch 6 batch 50 loss: 0.006357\n",
      "epoch 6 batch 100 loss: 0.019289\n",
      "epoch 6 batch 150 loss: 0.004127\n",
      "epoch 6 batch 200 loss: 0.045227\n",
      "epoch 6 batch 250 loss: 0.024094\n",
      "epoch 6 batch 300 loss: 0.003361\n",
      "epoch 6 batch 350 loss: 0.008638\n",
      "epoch 6 batch 400 loss: 0.042183\n",
      "epoch 6 batch 450 loss: 0.021720\n",
      "epoch 6 batch 500 loss: 0.003590\n",
      "epoch 6 batch 550 loss: 0.020037\n",
      "epoch 6 batch 600 loss: 0.016319\n",
      "epoch 6 batch 650 loss: 0.001776\n",
      "epoch 6 batch 700 loss: 0.011974\n",
      "epoch 6 batch 750 loss: 0.021411\n",
      "epoch 6 batch 800 loss: 0.020925\n",
      "epoch 6 batch 850 loss: 0.011933\n",
      "epoch 6 batch 900 loss: 0.009100\n",
      "epoch 6 batch 950 loss: 0.235326\n",
      "validation accuracy: 0.971100\n",
      "test accuracy: 0.967300\n",
      "optimal accuracy: 0.971100\n",
      "epoch 7 batch 0 loss: 0.008704\n",
      "epoch 7 batch 50 loss: 0.000158\n",
      "epoch 7 batch 100 loss: 0.004525\n",
      "epoch 7 batch 150 loss: 0.007882\n",
      "epoch 7 batch 200 loss: 0.043699\n",
      "epoch 7 batch 250 loss: 0.048484\n",
      "epoch 7 batch 300 loss: 0.016592\n",
      "epoch 7 batch 350 loss: 0.017874\n",
      "epoch 7 batch 400 loss: 0.018436\n",
      "epoch 7 batch 450 loss: 0.008210\n",
      "epoch 7 batch 500 loss: 0.000504\n",
      "epoch 7 batch 550 loss: 0.011797\n",
      "epoch 7 batch 600 loss: 0.009029\n",
      "epoch 7 batch 650 loss: 0.002251\n",
      "epoch 7 batch 700 loss: 0.031321\n",
      "epoch 7 batch 750 loss: 0.007827\n",
      "epoch 7 batch 800 loss: 0.013942\n",
      "epoch 7 batch 850 loss: 0.005601\n",
      "epoch 7 batch 900 loss: 0.031731\n",
      "epoch 7 batch 950 loss: 0.021045\n",
      "validation accuracy: 0.973500\n",
      "test accuracy: 0.970300\n",
      "optimal accuracy: 0.973500\n",
      "epoch 8 batch 0 loss: 0.011617\n",
      "epoch 8 batch 50 loss: 0.000126\n",
      "epoch 8 batch 100 loss: 0.039365\n",
      "epoch 8 batch 150 loss: 0.000847\n",
      "epoch 8 batch 200 loss: 0.015943\n",
      "epoch 8 batch 250 loss: 0.022087\n",
      "epoch 8 batch 300 loss: 0.001407\n",
      "epoch 8 batch 350 loss: 0.001587\n",
      "epoch 8 batch 400 loss: 0.037912\n",
      "epoch 8 batch 450 loss: 0.078485\n",
      "epoch 8 batch 500 loss: 0.001591\n",
      "epoch 8 batch 550 loss: 0.022468\n",
      "epoch 8 batch 600 loss: 0.086843\n",
      "epoch 8 batch 650 loss: 0.013036\n",
      "epoch 8 batch 700 loss: 0.004904\n",
      "epoch 8 batch 750 loss: 0.003059\n",
      "epoch 8 batch 800 loss: 0.004882\n",
      "epoch 8 batch 850 loss: 0.005501\n",
      "epoch 8 batch 900 loss: 0.041856\n",
      "epoch 8 batch 950 loss: 0.016968\n",
      "validation accuracy: 0.972000\n",
      "test accuracy: 0.970300\n",
      "optimal accuracy: 0.973500\n",
      "epoch 9 batch 0 loss: 0.011617\n",
      "epoch 9 batch 50 loss: 0.000126\n",
      "epoch 9 batch 100 loss: 0.039365\n",
      "epoch 9 batch 150 loss: 0.000847\n",
      "epoch 9 batch 200 loss: 0.015943\n",
      "epoch 9 batch 250 loss: 0.022087\n",
      "epoch 9 batch 300 loss: 0.001407\n",
      "epoch 9 batch 350 loss: 0.001587\n",
      "epoch 9 batch 400 loss: 0.037912\n",
      "epoch 9 batch 450 loss: 0.078485\n",
      "epoch 9 batch 500 loss: 0.001591\n",
      "epoch 9 batch 550 loss: 0.022468\n",
      "epoch 9 batch 600 loss: 0.086843\n",
      "epoch 9 batch 650 loss: 0.013036\n",
      "epoch 9 batch 700 loss: 0.004904\n",
      "epoch 9 batch 750 loss: 0.003059\n",
      "epoch 9 batch 800 loss: 0.004882\n",
      "epoch 9 batch 850 loss: 0.005501\n",
      "epoch 9 batch 900 loss: 0.041856\n",
      "epoch 9 batch 950 loss: 0.016968\n",
      "validation accuracy: 0.972000\n",
      "test accuracy: 0.970300\n",
      "optimal accuracy: 0.973500\n",
      "learning rate decayed to 0.186300\n",
      "epoch 10 batch 0 loss: 0.011617\n",
      "epoch 10 batch 50 loss: 0.000181\n",
      "epoch 10 batch 100 loss: 0.046645\n",
      "epoch 10 batch 150 loss: 0.001148\n",
      "epoch 10 batch 200 loss: 0.017129\n",
      "epoch 10 batch 250 loss: 0.004166\n",
      "epoch 10 batch 300 loss: 0.002127\n",
      "epoch 10 batch 350 loss: 0.002230\n",
      "epoch 10 batch 400 loss: 0.011312\n",
      "epoch 10 batch 450 loss: 0.059487\n",
      "epoch 10 batch 500 loss: 0.002206\n",
      "epoch 10 batch 550 loss: 0.009849\n",
      "epoch 10 batch 600 loss: 0.013665\n",
      "epoch 10 batch 650 loss: 0.003955\n",
      "epoch 10 batch 700 loss: 0.008241\n",
      "epoch 10 batch 750 loss: 0.002850\n",
      "epoch 10 batch 800 loss: 0.072298\n",
      "epoch 10 batch 850 loss: 0.007652\n",
      "epoch 10 batch 900 loss: 0.016004\n",
      "epoch 10 batch 950 loss: 0.010704\n",
      "validation accuracy: 0.972000\n",
      "test accuracy: 0.970300\n",
      "optimal accuracy: 0.973500\n",
      "epoch 11 batch 0 loss: 0.011617\n",
      "epoch 11 batch 50 loss: 0.000181\n",
      "epoch 11 batch 100 loss: 0.046645\n",
      "epoch 11 batch 150 loss: 0.001148\n",
      "epoch 11 batch 200 loss: 0.017129\n",
      "epoch 11 batch 250 loss: 0.004166\n",
      "epoch 11 batch 300 loss: 0.002127\n",
      "epoch 11 batch 350 loss: 0.002230\n",
      "epoch 11 batch 400 loss: 0.011312\n",
      "epoch 11 batch 450 loss: 0.059487\n",
      "epoch 11 batch 500 loss: 0.002206\n",
      "epoch 11 batch 550 loss: 0.009849\n",
      "epoch 11 batch 600 loss: 0.013665\n",
      "epoch 11 batch 650 loss: 0.003955\n",
      "epoch 11 batch 700 loss: 0.008241\n",
      "epoch 11 batch 750 loss: 0.002850\n",
      "epoch 11 batch 800 loss: 0.072298\n",
      "epoch 11 batch 850 loss: 0.007652\n",
      "epoch 11 batch 900 loss: 0.016004\n",
      "epoch 11 batch 950 loss: 0.010704\n",
      "validation accuracy: 0.972000\n",
      "test accuracy: 0.970300\n",
      "optimal accuracy: 0.973500\n",
      "epoch 12 batch 0 loss: 0.011617\n",
      "epoch 12 batch 50 loss: 0.000181\n",
      "epoch 12 batch 100 loss: 0.046645\n",
      "epoch 12 batch 150 loss: 0.001148\n",
      "epoch 12 batch 200 loss: 0.017129\n",
      "epoch 12 batch 250 loss: 0.004166\n",
      "epoch 12 batch 300 loss: 0.002127\n",
      "epoch 12 batch 350 loss: 0.002230\n",
      "epoch 12 batch 400 loss: 0.011312\n",
      "epoch 12 batch 450 loss: 0.059487\n",
      "epoch 12 batch 500 loss: 0.002206\n",
      "epoch 12 batch 550 loss: 0.009849\n",
      "epoch 12 batch 600 loss: 0.013665\n",
      "epoch 12 batch 650 loss: 0.003955\n",
      "epoch 12 batch 700 loss: 0.008241\n",
      "epoch 12 batch 750 loss: 0.002850\n",
      "epoch 12 batch 800 loss: 0.072298\n",
      "epoch 12 batch 850 loss: 0.007652\n",
      "epoch 12 batch 900 loss: 0.016004\n",
      "epoch 12 batch 950 loss: 0.010704\n",
      "validation accuracy: 0.972000\n",
      "test accuracy: 0.970300\n",
      "optimal accuracy: 0.973500\n",
      "epoch 13 batch 0 loss: 0.011617\n",
      "epoch 13 batch 50 loss: 0.000181\n",
      "epoch 13 batch 100 loss: 0.046645\n",
      "epoch 13 batch 150 loss: 0.001148\n",
      "epoch 13 batch 200 loss: 0.017129\n",
      "epoch 13 batch 250 loss: 0.004166\n",
      "epoch 13 batch 300 loss: 0.002127\n",
      "epoch 13 batch 350 loss: 0.002230\n",
      "epoch 13 batch 400 loss: 0.011312\n",
      "epoch 13 batch 450 loss: 0.059487\n",
      "epoch 13 batch 500 loss: 0.002206\n",
      "epoch 13 batch 550 loss: 0.009849\n",
      "epoch 13 batch 600 loss: 0.013665\n",
      "epoch 13 batch 650 loss: 0.003955\n",
      "epoch 13 batch 700 loss: 0.008241\n",
      "epoch 13 batch 750 loss: 0.002850\n",
      "epoch 13 batch 800 loss: 0.072298\n",
      "epoch 13 batch 850 loss: 0.007652\n",
      "epoch 13 batch 900 loss: 0.016004\n",
      "epoch 13 batch 950 loss: 0.010704\n",
      "validation accuracy: 0.972000\n",
      "test accuracy: 0.970300\n",
      "optimal accuracy: 0.973500\n",
      "epoch 14 batch 0 loss: 0.011617\n",
      "epoch 14 batch 50 loss: 0.000181\n",
      "epoch 14 batch 100 loss: 0.046645\n",
      "epoch 14 batch 150 loss: 0.001148\n",
      "epoch 14 batch 200 loss: 0.017129\n",
      "epoch 14 batch 250 loss: 0.004166\n",
      "epoch 14 batch 300 loss: 0.002127\n",
      "epoch 14 batch 350 loss: 0.002230\n",
      "epoch 14 batch 400 loss: 0.011312\n",
      "epoch 14 batch 450 loss: 0.059487\n",
      "epoch 14 batch 500 loss: 0.002206\n",
      "epoch 14 batch 550 loss: 0.009849\n",
      "epoch 14 batch 600 loss: 0.013665\n",
      "epoch 14 batch 650 loss: 0.003955\n",
      "epoch 14 batch 700 loss: 0.008241\n",
      "epoch 14 batch 750 loss: 0.002850\n",
      "epoch 14 batch 800 loss: 0.072298\n",
      "epoch 14 batch 850 loss: 0.007652\n",
      "epoch 14 batch 900 loss: 0.016004\n",
      "epoch 14 batch 950 loss: 0.010704\n",
      "validation accuracy: 0.972000\n",
      "test accuracy: 0.970300\n",
      "optimal accuracy: 0.973500\n",
      "learning rate decayed to 0.167670\n",
      "epoch 15 batch 0 loss: 0.011617\n",
      "epoch 15 batch 50 loss: 0.000293\n",
      "epoch 15 batch 100 loss: 0.021009\n",
      "epoch 15 batch 150 loss: 0.000867\n",
      "epoch 15 batch 200 loss: 0.017404\n",
      "epoch 15 batch 250 loss: 0.011419\n",
      "epoch 15 batch 300 loss: 0.006414\n",
      "epoch 15 batch 350 loss: 0.003301\n",
      "epoch 15 batch 400 loss: 0.018209\n",
      "epoch 15 batch 450 loss: 0.061020\n",
      "epoch 15 batch 500 loss: 0.001598\n",
      "epoch 15 batch 550 loss: 0.010382\n",
      "epoch 15 batch 600 loss: 0.012947\n",
      "epoch 15 batch 650 loss: 0.002040\n",
      "epoch 15 batch 700 loss: 0.011332\n",
      "epoch 15 batch 750 loss: 0.013766\n",
      "epoch 15 batch 800 loss: 0.088369\n",
      "epoch 15 batch 850 loss: 0.010313\n",
      "epoch 15 batch 900 loss: 0.001626\n",
      "epoch 15 batch 950 loss: 0.002572\n",
      "validation accuracy: 0.973800\n",
      "test accuracy: 0.972100\n",
      "optimal accuracy: 0.973800\n",
      "epoch 16 batch 0 loss: 0.000468\n",
      "epoch 16 batch 50 loss: 0.000070\n",
      "epoch 16 batch 100 loss: 0.002402\n",
      "epoch 16 batch 150 loss: 0.001820\n",
      "epoch 16 batch 200 loss: 0.008791\n",
      "epoch 16 batch 250 loss: 0.025049\n",
      "epoch 16 batch 300 loss: 0.000723\n",
      "epoch 16 batch 350 loss: 0.005811\n",
      "epoch 16 batch 400 loss: 0.025536\n",
      "epoch 16 batch 450 loss: 0.003932\n",
      "epoch 16 batch 500 loss: 0.001711\n",
      "epoch 16 batch 550 loss: 0.014400\n",
      "epoch 16 batch 600 loss: 0.004309\n",
      "epoch 16 batch 650 loss: 0.012797\n",
      "epoch 16 batch 700 loss: 0.001367\n",
      "epoch 16 batch 750 loss: 0.003808\n",
      "epoch 16 batch 800 loss: 0.011279\n",
      "epoch 16 batch 850 loss: 0.003002\n",
      "epoch 16 batch 900 loss: 0.014280\n",
      "epoch 16 batch 950 loss: 0.010075\n",
      "validation accuracy: 0.974900\n",
      "test accuracy: 0.971600\n",
      "optimal accuracy: 0.974900\n",
      "epoch 17 batch 0 loss: 0.000529\n",
      "epoch 17 batch 50 loss: 0.000040\n",
      "epoch 17 batch 100 loss: 0.005813\n",
      "epoch 17 batch 150 loss: 0.001604\n",
      "epoch 17 batch 200 loss: 0.011685\n",
      "epoch 17 batch 250 loss: 0.001065\n",
      "epoch 17 batch 300 loss: 0.000421\n",
      "epoch 17 batch 350 loss: 0.001922\n",
      "epoch 17 batch 400 loss: 0.008200\n",
      "epoch 17 batch 450 loss: 0.063544\n",
      "epoch 17 batch 500 loss: 0.000392\n",
      "epoch 17 batch 550 loss: 0.015837\n",
      "epoch 17 batch 600 loss: 0.003509\n",
      "epoch 17 batch 650 loss: 0.004829\n",
      "epoch 17 batch 700 loss: 0.006051\n",
      "epoch 17 batch 750 loss: 0.034544\n",
      "epoch 17 batch 800 loss: 0.002171\n",
      "epoch 17 batch 850 loss: 0.002327\n",
      "epoch 17 batch 900 loss: 0.048055\n",
      "epoch 17 batch 950 loss: 0.004300\n",
      "validation accuracy: 0.978000\n",
      "test accuracy: 0.975600\n",
      "optimal accuracy: 0.978000\n",
      "epoch 18 batch 0 loss: 0.003751\n",
      "epoch 18 batch 50 loss: 0.004205\n",
      "epoch 18 batch 100 loss: 0.087738\n",
      "epoch 18 batch 150 loss: 0.002191\n",
      "epoch 18 batch 200 loss: 0.002690\n",
      "epoch 18 batch 250 loss: 0.019220\n",
      "epoch 18 batch 300 loss: 0.001391\n",
      "epoch 18 batch 350 loss: 0.004659\n",
      "epoch 18 batch 400 loss: 0.006136\n",
      "epoch 18 batch 450 loss: 0.003719\n",
      "epoch 18 batch 500 loss: 0.000132\n",
      "epoch 18 batch 550 loss: 0.002250\n",
      "epoch 18 batch 600 loss: 0.001345\n",
      "epoch 18 batch 650 loss: 0.006268\n",
      "epoch 18 batch 700 loss: 0.002453\n",
      "epoch 18 batch 750 loss: 0.003253\n",
      "epoch 18 batch 800 loss: 0.004009\n",
      "epoch 18 batch 850 loss: 0.004748\n",
      "epoch 18 batch 900 loss: 0.001921\n",
      "epoch 18 batch 950 loss: 0.005016\n",
      "validation accuracy: 0.975500\n",
      "test accuracy: 0.975600\n",
      "optimal accuracy: 0.978000\n",
      "epoch 19 batch 0 loss: 0.003751\n",
      "epoch 19 batch 50 loss: 0.004205\n",
      "epoch 19 batch 100 loss: 0.087738\n",
      "epoch 19 batch 150 loss: 0.002191\n",
      "epoch 19 batch 200 loss: 0.002690\n",
      "epoch 19 batch 250 loss: 0.019220\n",
      "epoch 19 batch 300 loss: 0.001391\n",
      "epoch 19 batch 350 loss: 0.004659\n",
      "epoch 19 batch 400 loss: 0.006136\n",
      "epoch 19 batch 450 loss: 0.003719\n",
      "epoch 19 batch 500 loss: 0.000132\n",
      "epoch 19 batch 550 loss: 0.002250\n",
      "epoch 19 batch 600 loss: 0.001345\n",
      "epoch 19 batch 650 loss: 0.006268\n",
      "epoch 19 batch 700 loss: 0.002453\n",
      "epoch 19 batch 750 loss: 0.003253\n",
      "epoch 19 batch 800 loss: 0.004009\n",
      "epoch 19 batch 850 loss: 0.004748\n",
      "epoch 19 batch 900 loss: 0.001921\n",
      "epoch 19 batch 950 loss: 0.005016\n",
      "validation accuracy: 0.975500\n",
      "test accuracy: 0.975600\n",
      "optimal accuracy: 0.978000\n",
      "learning rate decayed to 0.150903\n",
      "epoch 20 batch 0 loss: 0.003751\n",
      "epoch 20 batch 50 loss: 0.005141\n",
      "epoch 20 batch 100 loss: 0.099846\n",
      "epoch 20 batch 150 loss: 0.001961\n",
      "epoch 20 batch 200 loss: 0.003768\n",
      "epoch 20 batch 250 loss: 0.001301\n",
      "epoch 20 batch 300 loss: 0.000288\n",
      "epoch 20 batch 350 loss: 0.000656\n",
      "epoch 20 batch 400 loss: 0.004455\n",
      "epoch 20 batch 450 loss: 0.023542\n",
      "epoch 20 batch 500 loss: 0.000173\n",
      "epoch 20 batch 550 loss: 0.001749\n",
      "epoch 20 batch 600 loss: 0.003199\n",
      "epoch 20 batch 650 loss: 0.003328\n",
      "epoch 20 batch 700 loss: 0.003656\n",
      "epoch 20 batch 750 loss: 0.002064\n",
      "epoch 20 batch 800 loss: 0.002518\n",
      "epoch 20 batch 850 loss: 0.002864\n",
      "epoch 20 batch 900 loss: 0.000391\n",
      "epoch 20 batch 950 loss: 0.007290\n",
      "validation accuracy: 0.978500\n",
      "test accuracy: 0.977100\n",
      "optimal accuracy: 0.978500\n",
      "epoch 21 batch 0 loss: 0.001639\n",
      "epoch 21 batch 50 loss: 0.000066\n",
      "epoch 21 batch 100 loss: 0.001603\n",
      "epoch 21 batch 150 loss: 0.003642\n",
      "epoch 21 batch 200 loss: 0.001239\n",
      "epoch 21 batch 250 loss: 0.011532\n",
      "epoch 21 batch 300 loss: 0.001221\n",
      "epoch 21 batch 350 loss: 0.002145\n",
      "epoch 21 batch 400 loss: 0.006835\n",
      "epoch 21 batch 450 loss: 0.013636\n",
      "epoch 21 batch 500 loss: 0.000134\n",
      "epoch 21 batch 550 loss: 0.002736\n",
      "epoch 21 batch 600 loss: 0.005918\n",
      "epoch 21 batch 650 loss: 0.009330\n",
      "epoch 21 batch 700 loss: 0.004516\n",
      "epoch 21 batch 750 loss: 0.003183\n",
      "epoch 21 batch 800 loss: 0.001496\n",
      "epoch 21 batch 850 loss: 0.003757\n",
      "epoch 21 batch 900 loss: 0.000339\n",
      "epoch 21 batch 950 loss: 0.003855\n",
      "validation accuracy: 0.979200\n",
      "test accuracy: 0.976700\n",
      "optimal accuracy: 0.979200\n",
      "epoch 22 batch 0 loss: 0.000919\n",
      "epoch 22 batch 50 loss: 0.000022\n",
      "epoch 22 batch 100 loss: 0.005145\n",
      "epoch 22 batch 150 loss: 0.000399\n",
      "epoch 22 batch 200 loss: 0.011948\n",
      "epoch 22 batch 250 loss: 0.000595\n",
      "epoch 22 batch 300 loss: 0.000381\n",
      "epoch 22 batch 350 loss: 0.000156\n",
      "epoch 22 batch 400 loss: 0.001399\n",
      "epoch 22 batch 450 loss: 0.000732\n",
      "epoch 22 batch 500 loss: 0.000073\n",
      "epoch 22 batch 550 loss: 0.005798\n",
      "epoch 22 batch 600 loss: 0.001303\n",
      "epoch 22 batch 650 loss: 0.000540\n",
      "epoch 22 batch 700 loss: 0.000135\n",
      "epoch 22 batch 750 loss: 0.002165\n",
      "epoch 22 batch 800 loss: 0.001370\n",
      "epoch 22 batch 850 loss: 0.003084\n",
      "epoch 22 batch 900 loss: 0.000331\n",
      "epoch 22 batch 950 loss: 0.001660\n",
      "validation accuracy: 0.978500\n",
      "test accuracy: 0.976700\n",
      "optimal accuracy: 0.979200\n",
      "epoch 23 batch 0 loss: 0.000919\n",
      "epoch 23 batch 50 loss: 0.000022\n",
      "epoch 23 batch 100 loss: 0.005145\n",
      "epoch 23 batch 150 loss: 0.000399\n",
      "epoch 23 batch 200 loss: 0.011948\n",
      "epoch 23 batch 250 loss: 0.000595\n",
      "epoch 23 batch 300 loss: 0.000381\n",
      "epoch 23 batch 350 loss: 0.000156\n",
      "epoch 23 batch 400 loss: 0.001399\n",
      "epoch 23 batch 450 loss: 0.000732\n",
      "epoch 23 batch 500 loss: 0.000073\n",
      "epoch 23 batch 550 loss: 0.005798\n",
      "epoch 23 batch 600 loss: 0.001303\n",
      "epoch 23 batch 650 loss: 0.000540\n",
      "epoch 23 batch 700 loss: 0.000135\n",
      "epoch 23 batch 750 loss: 0.002165\n",
      "epoch 23 batch 800 loss: 0.001370\n",
      "epoch 23 batch 850 loss: 0.003084\n",
      "epoch 23 batch 900 loss: 0.000331\n",
      "epoch 23 batch 950 loss: 0.001660\n",
      "validation accuracy: 0.978500\n",
      "test accuracy: 0.976700\n",
      "optimal accuracy: 0.979200\n",
      "epoch 24 batch 0 loss: 0.000919\n",
      "epoch 24 batch 50 loss: 0.000022\n",
      "epoch 24 batch 100 loss: 0.005145\n",
      "epoch 24 batch 150 loss: 0.000399\n",
      "epoch 24 batch 200 loss: 0.011948\n",
      "epoch 24 batch 250 loss: 0.000595\n",
      "epoch 24 batch 300 loss: 0.000381\n",
      "epoch 24 batch 350 loss: 0.000156\n",
      "epoch 24 batch 400 loss: 0.001399\n",
      "epoch 24 batch 450 loss: 0.000732\n",
      "epoch 24 batch 500 loss: 0.000073\n",
      "epoch 24 batch 550 loss: 0.005798\n",
      "epoch 24 batch 600 loss: 0.001303\n",
      "epoch 24 batch 650 loss: 0.000540\n",
      "epoch 24 batch 700 loss: 0.000135\n",
      "epoch 24 batch 750 loss: 0.002165\n",
      "epoch 24 batch 800 loss: 0.001370\n",
      "epoch 24 batch 850 loss: 0.003084\n",
      "epoch 24 batch 900 loss: 0.000331\n",
      "epoch 24 batch 950 loss: 0.001660\n",
      "validation accuracy: 0.978500\n",
      "test accuracy: 0.976700\n",
      "optimal accuracy: 0.979200\n",
      "learning rate decayed to 0.135813\n",
      "epoch 25 batch 0 loss: 0.000919\n",
      "epoch 25 batch 50 loss: 0.000022\n",
      "epoch 25 batch 100 loss: 0.006448\n",
      "epoch 25 batch 150 loss: 0.000412\n",
      "epoch 25 batch 200 loss: 0.013441\n",
      "epoch 25 batch 250 loss: 0.000416\n",
      "epoch 25 batch 300 loss: 0.000370\n",
      "epoch 25 batch 350 loss: 0.000142\n",
      "epoch 25 batch 400 loss: 0.001229\n",
      "epoch 25 batch 450 loss: 0.000999\n",
      "epoch 25 batch 500 loss: 0.000187\n",
      "epoch 25 batch 550 loss: 0.015233\n",
      "epoch 25 batch 600 loss: 0.006642\n",
      "epoch 25 batch 650 loss: 0.000548\n",
      "epoch 25 batch 700 loss: 0.000195\n",
      "epoch 25 batch 750 loss: 0.004434\n",
      "epoch 25 batch 800 loss: 0.000538\n",
      "epoch 25 batch 850 loss: 0.003324\n",
      "epoch 25 batch 900 loss: 0.000456\n",
      "epoch 25 batch 950 loss: 0.003956\n",
      "validation accuracy: 0.979300\n",
      "test accuracy: 0.976500\n",
      "optimal accuracy: 0.979300\n",
      "epoch 26 batch 0 loss: 0.002358\n",
      "epoch 26 batch 50 loss: 0.000070\n",
      "epoch 26 batch 100 loss: 0.008507\n",
      "epoch 26 batch 150 loss: 0.000249\n",
      "epoch 26 batch 200 loss: 0.000629\n",
      "epoch 26 batch 250 loss: 0.000208\n",
      "epoch 26 batch 300 loss: 0.001129\n",
      "epoch 26 batch 350 loss: 0.000170\n",
      "epoch 26 batch 400 loss: 0.000408\n",
      "epoch 26 batch 450 loss: 0.000453\n",
      "epoch 26 batch 500 loss: 0.000053\n",
      "epoch 26 batch 550 loss: 0.001054\n",
      "epoch 26 batch 600 loss: 0.000148\n",
      "epoch 26 batch 650 loss: 0.000336\n",
      "epoch 26 batch 700 loss: 0.000601\n",
      "epoch 26 batch 750 loss: 0.000805\n",
      "epoch 26 batch 800 loss: 0.000179\n",
      "epoch 26 batch 850 loss: 0.001069\n",
      "epoch 26 batch 900 loss: 0.000118\n",
      "epoch 26 batch 950 loss: 0.000041\n",
      "validation accuracy: 0.978200\n",
      "test accuracy: 0.976500\n",
      "optimal accuracy: 0.979300\n",
      "epoch 27 batch 0 loss: 0.002358\n",
      "epoch 27 batch 50 loss: 0.000070\n",
      "epoch 27 batch 100 loss: 0.008507\n",
      "epoch 27 batch 150 loss: 0.000249\n",
      "epoch 27 batch 200 loss: 0.000629\n",
      "epoch 27 batch 250 loss: 0.000208\n",
      "epoch 27 batch 300 loss: 0.001129\n",
      "epoch 27 batch 350 loss: 0.000170\n",
      "epoch 27 batch 400 loss: 0.000408\n",
      "epoch 27 batch 450 loss: 0.000453\n",
      "epoch 27 batch 500 loss: 0.000053\n",
      "epoch 27 batch 550 loss: 0.001054\n",
      "epoch 27 batch 600 loss: 0.000148\n",
      "epoch 27 batch 650 loss: 0.000336\n",
      "epoch 27 batch 700 loss: 0.000601\n",
      "epoch 27 batch 750 loss: 0.000805\n",
      "epoch 27 batch 800 loss: 0.000179\n",
      "epoch 27 batch 850 loss: 0.001069\n",
      "epoch 27 batch 900 loss: 0.000118\n",
      "epoch 27 batch 950 loss: 0.000041\n",
      "validation accuracy: 0.978200\n",
      "test accuracy: 0.976500\n",
      "optimal accuracy: 0.979300\n",
      "epoch 28 batch 0 loss: 0.002358\n",
      "epoch 28 batch 50 loss: 0.000070\n",
      "epoch 28 batch 100 loss: 0.008507\n",
      "epoch 28 batch 150 loss: 0.000249\n",
      "epoch 28 batch 200 loss: 0.000629\n",
      "epoch 28 batch 250 loss: 0.000208\n",
      "epoch 28 batch 300 loss: 0.001129\n",
      "epoch 28 batch 350 loss: 0.000170\n",
      "epoch 28 batch 400 loss: 0.000408\n",
      "epoch 28 batch 450 loss: 0.000453\n",
      "epoch 28 batch 500 loss: 0.000053\n",
      "epoch 28 batch 550 loss: 0.001054\n",
      "epoch 28 batch 600 loss: 0.000148\n",
      "epoch 28 batch 650 loss: 0.000336\n",
      "epoch 28 batch 700 loss: 0.000601\n",
      "epoch 28 batch 750 loss: 0.000805\n",
      "epoch 28 batch 800 loss: 0.000179\n",
      "epoch 28 batch 850 loss: 0.001069\n",
      "epoch 28 batch 900 loss: 0.000118\n",
      "epoch 28 batch 950 loss: 0.000041\n",
      "validation accuracy: 0.978200\n",
      "test accuracy: 0.976500\n",
      "optimal accuracy: 0.979300\n",
      "epoch 29 batch 0 loss: 0.002358\n",
      "epoch 29 batch 50 loss: 0.000070\n",
      "epoch 29 batch 100 loss: 0.008507\n",
      "epoch 29 batch 150 loss: 0.000249\n",
      "epoch 29 batch 200 loss: 0.000629\n",
      "epoch 29 batch 250 loss: 0.000208\n",
      "epoch 29 batch 300 loss: 0.001129\n",
      "epoch 29 batch 350 loss: 0.000170\n",
      "epoch 29 batch 400 loss: 0.000408\n",
      "epoch 29 batch 450 loss: 0.000453\n",
      "epoch 29 batch 500 loss: 0.000053\n",
      "epoch 29 batch 550 loss: 0.001054\n",
      "epoch 29 batch 600 loss: 0.000148\n",
      "epoch 29 batch 650 loss: 0.000336\n",
      "epoch 29 batch 700 loss: 0.000601\n",
      "epoch 29 batch 750 loss: 0.000805\n",
      "epoch 29 batch 800 loss: 0.000179\n",
      "epoch 29 batch 850 loss: 0.001069\n",
      "epoch 29 batch 900 loss: 0.000118\n",
      "epoch 29 batch 950 loss: 0.000041\n",
      "validation accuracy: 0.978200\n",
      "test accuracy: 0.976500\n",
      "optimal accuracy: 0.979300\n",
      "learning rate decayed to 0.122231\n",
      "[0.9522, 0.9629, 0.9644, 0.968, 0.9637, 0.9696, 0.9711, 0.9735, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.972, 0.9738, 0.9749, 0.978, 0.9755, 0.9755, 0.9785, 0.9792, 0.9785, 0.9785, 0.9785, 0.9793, 0.9782, 0.9782, 0.9782, 0.9782]\n"
     ]
    }
   ],
   "source": [
    "from constructor import *\n",
    "from solver import *\n",
    "import utils\n",
    "\n",
    "model_name = 'mlp'\n",
    "act_mode = 'relu'\n",
    "model_setting = {\n",
    "#     'model_structure': [784, 256, 64, 10],\n",
    "    'model_structure': [784, 1024, 1024, 1024, 10],\n",
    "    'act_mode': [act_mode, act_mode, act_mode],\n",
    "    'device': 1,\n",
    "    'weight_init': 0.01,\n",
    "    'bias_init': 0.1,\n",
    "    'lower_bound': -1.0,\n",
    "    'upper_bound': 1.0,\n",
    "}\n",
    "model = build_model(model_name, model_setting)\n",
    "\n",
    "solver_setting = {\n",
    "    'epoch': 30,\n",
    "    'batch_size': 50,\n",
    "    'decay_rate': 0.9,\n",
    "    'decay_interval': 5,\n",
    "    'optimizer': 'sgd',\n",
    "    'update_setting': {'learning_rate': 0.23},\n",
    "}\n",
    "solver = Solver(model, data, **solver_setting)\n",
    "accuracy_record = solver.train()\n",
    "utils.record_settings('%s-%s' % (model_name, act_mode), model_setting, solver_setting)\n",
    "print accuracy_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x7f6e5a3d2050>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnIAAAIXCAYAAAAYF7N8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmQwRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6ec0999990>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Validation Accuracy\n",
    "plt.plot(range(len(accuracy_record)), accuracy_record)\n",
    "plt.suptitle('Validation Accuracy', fontsize=14, fontweight='bold')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Program Over Flag\n"
     ]
    }
   ],
   "source": [
    "#TODO: Current graphs are epoch-wise sampling from a certain batch in one epoch. Do a full epoch \n",
    "\n",
    "print 'Program Over Flag'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
